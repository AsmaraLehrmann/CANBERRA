{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a513b53",
   "metadata": {},
   "source": [
    "## First, extract radioisotope data from Canberra PDFs\n",
    "\n",
    "Run cell and follow instructions. Make sure to add the .csv ending to the output file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937424bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_pdf_values(folder_path, output_csv_path, parse_numbers=False):\n",
    "    combined_data = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".PDF\") or filename.endswith(\".pdf\"):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            file_name_without_extension = os.path.splitext(filename)[0]\n",
    "\n",
    "            # Initialize variables to store isotopes' values\n",
    "            pb210 = Bi214 = Pb214 = ptsrc_pb210 = None\n",
    "\n",
    "            # Read in the PDF file\n",
    "            try:\n",
    "                reader = PdfReader(file_path)\n",
    "                if len(reader.pages) < 3:\n",
    "                    print(f\"PDF file '{filename}' has less than 3 pages. Skipping.\")\n",
    "                    continue\n",
    "                page = reader.pages[2]\n",
    "                text = page.extract_text()\n",
    "                lines = text.split('\\n')\n",
    "\n",
    "                # Check if the filename starts with 'PtSrc_'\n",
    "                if filename.startswith(\"PtSrc_\"):\n",
    "                    # Only extract Pb-210 value for PtSrc files\n",
    "                    for line in lines:\n",
    "                        if 'Pb-210' in line:\n",
    "                            ptsrc_pb210, PtSrc_Pb210error = line.split()[-2:]\n",
    "                            break  # Exit the loop after finding Pb-210\n",
    "                    # Store only Pb-210 values if found\n",
    "                    if ptsrc_pb210 is not None and PtSrc_Pb210error is not None:\n",
    "                        data = {'File': filename, 'Pb-210': float(ptsrc_pb210), 'Pb-210 error': float(PtSrc_Pb210error)}\n",
    "                    else:\n",
    "                        print(f\"Pb-210 not found in '{filename}'. Skipping.\")\n",
    "                        continue\n",
    "                else:\n",
    "                    # Extract values for other files\n",
    "                    for line in lines:\n",
    "                        if 'Pb-210' in line:\n",
    "                            pb210, pb210error = line.split()[-2:]\n",
    "                        elif 'Bi-214' in line:\n",
    "                            Bi214, Bi214error = line.split()[-2:]\n",
    "                        elif 'Pb-214' in line:\n",
    "                            Pb214, Pb214error = line.split()[-2:]\n",
    "\n",
    "                    # Store values only if they were found\n",
    "                    if pb210 is not None and pb210error is not None:\n",
    "                        data = {\n",
    "                            'File': filename,\n",
    "                            'Pb-210': float(pb210),\n",
    "                            'Pb-210 error': float(pb210error),\n",
    "                            'Bi-214': float(Bi214) if Bi214 else None,\n",
    "                            'Bi-214 error': float(Bi214error) if Bi214error else None,\n",
    "                            'Pb-214': float(Pb214) if Pb214 else None,\n",
    "                            'Pb-214 error': float(Pb214error) if Pb214error else None\n",
    "                        }\n",
    "                    else:\n",
    "                        print(f\"Pb-210 not found in '{filename}'. Skipping.\")\n",
    "                        continue\n",
    "\n",
    "                combined_data.append(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing PDF file '{filename}': {e}\")\n",
    "\n",
    "    # Create a DataFrame\n",
    "    combined_df = pd.DataFrame(combined_data)\n",
    "\n",
    "    # Extract the numeric part before the hyphen ('-') for sorting\n",
    "    def extract_numeric_prefix(file_name):\n",
    "        try:\n",
    "            # Split the file name based on the underscore and hyphen and take the numeric part\n",
    "            prefix = file_name.split('_')[-1].split('-')[0]\n",
    "            return int(prefix)  # Convert the prefix to an integer\n",
    "        except ValueError:\n",
    "            return float('nan')  # Return NaN if the prefix is not numeric\n",
    "\n",
    "    # Apply sorting based on the extracted numeric part\n",
    "    combined_df['File_order'] = combined_df['File'].apply(extract_numeric_prefix)\n",
    "    \n",
    "    # Sort by the numeric part extracted\n",
    "    combined_df = combined_df.sort_values(by='File_order')\n",
    "\n",
    "    # Remove the 'File_order' column before saving\n",
    "    combined_df = combined_df.drop(columns=['File_order'])\n",
    "\n",
    "    # Optional: If you want to parse numbers into floats (e.g., for columns with values)\n",
    "    if parse_numbers:\n",
    "        combined_df[['Pb-210', 'Bi-214', 'Pb-214']] = combined_df[['Pb-210', 'Bi-214', 'Pb-214']].apply(lambda x: x.str.strip().astype(float))\n",
    "\n",
    "    combined_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Example usage:\n",
    "folder_path = input(\"Enter the folder path: \")  # Ask for folder path\n",
    "output_csv_path = input(\"Enter the output CSV file path: \")  # Ask for the output file path\n",
    "extract_pdf_values(folder_path, output_csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ac233",
   "metadata": {},
   "source": [
    "# Open the output .csv file\n",
    "\n",
    "Check to make sure all radioisotope data translated correctly. \n",
    "\n",
    "# Create two new columns and add data accordingly\n",
    "- ptsrc_pb210,\n",
    "- ptsrc_pb210 error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8f82fd",
   "metadata": {},
   "source": [
    "# Next, make sure your .csv files are correctly labeled for the age model calculations. \n",
    "\n",
    "Sample weights should have the following headings: \n",
    "- Core, Top of interval (cm),\n",
    "- Center point of interval,\n",
    "- Base of interval (cm),\n",
    "- sediment weight (g) \n",
    "\n",
    "Radioisotope data should have the following headings\n",
    "- File,\n",
    "- Pb-210,\n",
    "- Pb-210 error,\n",
    "- Bi-214,\n",
    "- Bi-214 error,\n",
    "- Pb-214,\n",
    "- Pb-214 error,\n",
    "- ptsrc_pb210,\n",
    "- ptsrc_pb210 error\n",
    "\n",
    "Replace '/path.csv' and 'output_with_ages.csv' accordingly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776436fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path to the sample weight CSV file (e.g., /path/weights.csv): /Users/alehrmann/Documents/Research_files/West_Antarctica/Amundsen_Sea/NBP2002KC72_weights.csv\n",
      "Enter the path to the Canberra data CSV file (e.g., /path/canberra.csv): /Users/alehrmann/Documents/Research_files/West_Antarctica/Amundsen_Sea/NBP2002 KC72.csv\n",
      "Enter the name for the output CSV file (e.g., output_with_ages.csv): AgeModel_output_NBP2002KC72\n",
      "Enter the year of core (e.g., 2023): 2020\n",
      "Calculations completed, data exported to 'AgeModel_output_NBP2002KC72'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Prompt user for file paths and output file name\n",
    "csv1_path = input(\"Enter the path to the sample weight CSV file (e.g., /path/weights.csv): \")\n",
    "csv2_path = input(\"Enter the path to the Canberra data CSV file (e.g., /path/canberra.csv): \")\n",
    "output_file_name = input(\"Enter the name for the output CSV file (e.g., output_with_ages.csv): \")\n",
    "\n",
    "# Load the CSV files\n",
    "csv1 = pd.read_csv(csv1_path)\n",
    "csv2 = pd.read_csv(csv2_path)\n",
    "\n",
    "# Extract 'Center point of interval' from .csv 2 based on the median of the last two digits in 'File'\n",
    "csv2['Center point of interval'] = csv2['File'].apply(\n",
    "    lambda x: np.median([int(num) for num in re.findall(r'\\d+', x.split('_')[-1])])\n",
    ")\n",
    "\n",
    "# Merge CSV files based on 'Center point of interval'\n",
    "data = pd.merge(csv1, csv2, on='Center point of interval', how='left')  # Merge using the new 'Center point of interval'\n",
    "\n",
    "# Now proceed with the calculations based on your updated requirements\n",
    "\n",
    "# Extract the 'year of core' as input\n",
    "year_of_core = int(input(\"Enter the year of core (e.g., 2023): \"))\n",
    "\n",
    "# Calculate columns\n",
    "data['Pb-210 activity (Bq/g)'] = data['Pb-210']/data['sediment weight (g)']\n",
    "data['Pb-210 correction factor'] = data['ptsrc_pb210'] / 151031.56  # Correction factor for Pb-210\n",
    "data['Self absorb. Corrected Pb-210 activity (Bq/g)'] = data['Pb-210 activity (Bq/g)'] / data['Pb-210 correction factor'] # Calculate Self absorb. Corrected Pb-210 activity (Bq/g)\n",
    "data['Bi-214 activity (Bq/g)'] = data['Bi-214'] / data['sediment weight (g)']\n",
    "data['Pb-214 activity (Bq/g)'] = data['Pb-214'] / data['sediment weight (g)']\n",
    "\n",
    "# Averaged supported activity of Bi-214 and Pb-214\n",
    "data['Averaged supported activity of Bi-214 and Pb-214 (Bq/g)'] = (\n",
    "    data['Bi-214 activity (Bq/g)'] + data['Pb-214 activity (Bq/g)']\n",
    ") / 2\n",
    "\n",
    "# Calculate background activity uncertainty (Bq/g)\n",
    "data['Background activity uncertainty (Bq/g)'] = (\n",
    "    (data['Bi-214 error'] + data['Pb-214 error']) / 2\n",
    ") / data['sediment weight (g)']\n",
    "\n",
    "\n",
    "# Calculate Excess Pb-210 (Bq/g)\n",
    "data['Excess Pb-210 (Bq/g)'] = data['Self absorb. Corrected Pb-210 activity (Bq/g)'] - data['Averaged supported activity of Bi-214 and Pb-214 (Bq/g)']\n",
    "\n",
    "# Calculate surface activity (value of first interval's 'Excess Pb-210 (Bq/g)')\n",
    "data['Surface activity'] = data['Excess Pb-210 (Bq/g)'].iloc[0]\n",
    "\n",
    "# Calculate Age bp\n",
    "data['Age bp'] = (1 / 0.03114) * np.log(data['Surface activity'] / data['Excess Pb-210 (Bq/g)'])\n",
    "\n",
    "# Calculate 'calendar years pre year of core'\n",
    "data['calendar years pre year of core'] = year_of_core - data['Age bp']\n",
    "\n",
    "# Save the final DataFrame to a new CSV file\n",
    "data.to_csv(output_file_name, index=False)  # Save as user-defined file name\n",
    "\n",
    "print(f\"Calculations completed, data exported to '{output_file_name}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2d497d",
   "metadata": {},
   "source": [
    "# Check the output data. Does it make sense?\n",
    "\n",
    "# Now plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ccf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Get the core name from user input\n",
    "core_name = input(\"Enter the core name for the title: \")\n",
    "\n",
    "# Ask user for depths to label \"calendar years pre year of core\"\n",
    "depths_to_label_input = input(\"Enter the depths (comma-separated) where 'calendar years pre year of core' should be labeled (or type 'all' to label all intervals): \")\n",
    "\n",
    "# If the user types 'all', label all intervals\n",
    "if depths_to_label_input.lower() == 'all':\n",
    "    depths_to_label = data['Center point of interval'].tolist()  # Use all depth intervals\n",
    "else:\n",
    "    # Otherwise, parse the comma-separated depths\n",
    "    depths_to_label = [float(depth.strip()) for depth in depths_to_label_input.split(\",\")]\n",
    "\n",
    "# Define colors for the series and lighter shades for error bars\n",
    "excess_pb210_color = 'black'\n",
    "excess_pb210_error_color = mcolors.to_rgba(excess_pb210_color, alpha=0.3)  # Lighter black with transparency\n",
    "supported_activity_color = 'grey'\n",
    "supported_activity_error_color = mcolors.to_rgba(supported_activity_color, alpha=0.3)  # Lighter grey with transparency\n",
    "\n",
    "# Plot 1: Dynamic Core 210Pb Uncorrected Activity\n",
    "plt.figure(figsize=(3, 5))\n",
    "plt.errorbar(data['Pb-214 activity (Bq/g)'], data['Center point of interval'], \n",
    "             xerr=data['Pb-214 error'], fmt='-', color=excess_pb210_color, label='Pb-214 activity (Bq/unit)', \n",
    "             capsize=5, linewidth=2, ecolor=excess_pb210_error_color)  # Lightened error color\n",
    "plt.title(f\"{core_name} 210Pb Uncorrected Activity\", fontsize=16)\n",
    "plt.xlabel(\"Bq/unit\", fontsize=14)\n",
    "plt.ylabel(\"Depth (cm)\", fontsize=14)\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show depth from surface\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=1)  # Move legend below plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('core_210Pb_uncorrected_activity.pdf', format='pdf', bbox_inches='tight')  # Save as PDF\n",
    "plt.show()\n",
    "\n",
    "# Plot 2: Dynamic Core 210Pb Activity with error bars\n",
    "plt.figure(figsize=(5, 10))\n",
    "\n",
    "# Series 1: Excess Pb-210 (Bq/g) with error bars\n",
    "plt.errorbar(data['Excess Pb-210 (Bq/g)'], data['Center point of interval'], \n",
    "             xerr=data['Pb-210 error'], fmt='-', color=excess_pb210_color, label='Excess Pb-210 (Bq/g)', \n",
    "             capsize=5, linewidth=2, ecolor=excess_pb210_error_color)  # Lightened error color\n",
    "\n",
    "# Series 2: Averaged supported activity of Bi-214 and Pb-214 (Bq/g) with error bars\n",
    "plt.errorbar(data['Averaged supported activity of Bi-214 and Pb-214 (Bq/g)'], data['Center point of interval'], \n",
    "             xerr=data['Background activity uncertainty (Bq/g)'], fmt='-', color=supported_activity_color, \n",
    "             label='Averaged supported activity of Bi-214 and Pb-214 (Bq/g)', capsize=5, linewidth=2, \n",
    "             ecolor=supported_activity_error_color)  # Lightened error color\n",
    "\n",
    "# Label the selected depths with \"calendar years pre year of core\" from the data column\n",
    "for i, depth in enumerate(data['Center point of interval']):\n",
    "    if depth in depths_to_label:\n",
    "        # Get the corresponding 'calendar years pre year of core' value and convert to an integer for a clean label\n",
    "        year_value = data['calendar years pre year of core'].iloc[i]\n",
    "        \n",
    "        # Check if the value is NaN (and skip it if it is)\n",
    "        if not pd.isna(year_value):\n",
    "            year = int(year_value)\n",
    "            # Place the label next to Series 1 (Excess Pb-210) values at the specified depth\n",
    "            plt.text(data['Excess Pb-210 (Bq/g)'].iloc[i], depth, \n",
    "                     f'{year}', fontsize=10, color='black', verticalalignment='center')\n",
    "\n",
    "plt.title(f\"{core_name} 210Pb Activity [Bq/g]\", fontsize=16)\n",
    "plt.xlabel(\"Bq/unit\", fontsize=14)\n",
    "plt.ylabel(\"Depth (cm)\", fontsize=14)\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to show depth from surface\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=1)  # Move legend below plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('core_210Pb_activity_with_error_bars.pdf', format='pdf', bbox_inches='tight')  # Save as PDF\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
